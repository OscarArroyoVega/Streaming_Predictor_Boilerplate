{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9345794392523364,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009345794392523364,
      "grad_norm": 0.9251659512519836,
      "learning_rate": 4e-05,
      "loss": 2.7285,
      "step": 1
    },
    {
      "epoch": 0.018691588785046728,
      "grad_norm": 0.9661230444908142,
      "learning_rate": 8e-05,
      "loss": 2.7239,
      "step": 2
    },
    {
      "epoch": 0.028037383177570093,
      "grad_norm": 0.9437225461006165,
      "learning_rate": 0.00012,
      "loss": 2.7007,
      "step": 3
    },
    {
      "epoch": 0.037383177570093455,
      "grad_norm": 1.0052913427352905,
      "learning_rate": 0.00016,
      "loss": 2.5318,
      "step": 4
    },
    {
      "epoch": 0.04672897196261682,
      "grad_norm": 1.064764380455017,
      "learning_rate": 0.0002,
      "loss": 2.5494,
      "step": 5
    },
    {
      "epoch": 0.056074766355140186,
      "grad_norm": 1.1353256702423096,
      "learning_rate": 0.00019789473684210526,
      "loss": 2.2342,
      "step": 6
    },
    {
      "epoch": 0.06542056074766354,
      "grad_norm": 1.2691609859466553,
      "learning_rate": 0.00019578947368421054,
      "loss": 1.9599,
      "step": 7
    },
    {
      "epoch": 0.07476635514018691,
      "grad_norm": 1.2916268110275269,
      "learning_rate": 0.0001936842105263158,
      "loss": 1.6567,
      "step": 8
    },
    {
      "epoch": 0.08411214953271028,
      "grad_norm": 1.2098454236984253,
      "learning_rate": 0.00019157894736842104,
      "loss": 1.5471,
      "step": 9
    },
    {
      "epoch": 0.09345794392523364,
      "grad_norm": 1.234727382659912,
      "learning_rate": 0.00018947368421052632,
      "loss": 1.401,
      "step": 10
    },
    {
      "epoch": 0.102803738317757,
      "grad_norm": 1.3371853828430176,
      "learning_rate": 0.0001873684210526316,
      "loss": 1.1674,
      "step": 11
    },
    {
      "epoch": 0.11214953271028037,
      "grad_norm": 1.3186135292053223,
      "learning_rate": 0.00018526315789473685,
      "loss": 1.0595,
      "step": 12
    },
    {
      "epoch": 0.12149532710280374,
      "grad_norm": 1.217583179473877,
      "learning_rate": 0.0001831578947368421,
      "loss": 0.8576,
      "step": 13
    },
    {
      "epoch": 0.1308411214953271,
      "grad_norm": 3.41925311088562,
      "learning_rate": 0.00018105263157894739,
      "loss": 0.7926,
      "step": 14
    },
    {
      "epoch": 0.14018691588785046,
      "grad_norm": 0.9936519265174866,
      "learning_rate": 0.00017894736842105264,
      "loss": 0.6991,
      "step": 15
    },
    {
      "epoch": 0.14953271028037382,
      "grad_norm": 0.6224288940429688,
      "learning_rate": 0.0001768421052631579,
      "loss": 0.4995,
      "step": 16
    },
    {
      "epoch": 0.1588785046728972,
      "grad_norm": 0.7238072752952576,
      "learning_rate": 0.00017473684210526317,
      "loss": 0.6669,
      "step": 17
    },
    {
      "epoch": 0.16822429906542055,
      "grad_norm": 0.5553795099258423,
      "learning_rate": 0.00017263157894736842,
      "loss": 0.7333,
      "step": 18
    },
    {
      "epoch": 0.17757009345794392,
      "grad_norm": 0.6474925875663757,
      "learning_rate": 0.0001705263157894737,
      "loss": 0.6139,
      "step": 19
    },
    {
      "epoch": 0.18691588785046728,
      "grad_norm": 0.5426331162452698,
      "learning_rate": 0.00016842105263157895,
      "loss": 0.4469,
      "step": 20
    },
    {
      "epoch": 0.19626168224299065,
      "grad_norm": 0.7468681335449219,
      "learning_rate": 0.00016631578947368423,
      "loss": 0.6382,
      "step": 21
    },
    {
      "epoch": 0.205607476635514,
      "grad_norm": 0.4288803040981293,
      "learning_rate": 0.00016421052631578948,
      "loss": 0.6292,
      "step": 22
    },
    {
      "epoch": 0.21495327102803738,
      "grad_norm": 0.37665292620658875,
      "learning_rate": 0.00016210526315789473,
      "loss": 0.5084,
      "step": 23
    },
    {
      "epoch": 0.22429906542056074,
      "grad_norm": 0.3861042857170105,
      "learning_rate": 0.00016,
      "loss": 0.548,
      "step": 24
    },
    {
      "epoch": 0.2336448598130841,
      "grad_norm": 0.33774808049201965,
      "learning_rate": 0.00015789473684210527,
      "loss": 0.4632,
      "step": 25
    },
    {
      "epoch": 0.24299065420560748,
      "grad_norm": 0.353209525346756,
      "learning_rate": 0.00015578947368421052,
      "loss": 0.566,
      "step": 26
    },
    {
      "epoch": 0.2523364485981308,
      "grad_norm": 0.37043485045433044,
      "learning_rate": 0.0001536842105263158,
      "loss": 0.4759,
      "step": 27
    },
    {
      "epoch": 0.2616822429906542,
      "grad_norm": 0.3466007113456726,
      "learning_rate": 0.00015157894736842108,
      "loss": 0.5353,
      "step": 28
    },
    {
      "epoch": 0.27102803738317754,
      "grad_norm": 0.3315713703632355,
      "learning_rate": 0.00014947368421052633,
      "loss": 0.4948,
      "step": 29
    },
    {
      "epoch": 0.2803738317757009,
      "grad_norm": 0.389724463224411,
      "learning_rate": 0.00014736842105263158,
      "loss": 0.5002,
      "step": 30
    },
    {
      "epoch": 0.2897196261682243,
      "grad_norm": 0.3265851140022278,
      "learning_rate": 0.00014526315789473686,
      "loss": 0.6644,
      "step": 31
    },
    {
      "epoch": 0.29906542056074764,
      "grad_norm": 0.29133203625679016,
      "learning_rate": 0.0001431578947368421,
      "loss": 0.5043,
      "step": 32
    },
    {
      "epoch": 0.308411214953271,
      "grad_norm": 0.29229864478111267,
      "learning_rate": 0.00014105263157894736,
      "loss": 0.4911,
      "step": 33
    },
    {
      "epoch": 0.3177570093457944,
      "grad_norm": 0.34908610582351685,
      "learning_rate": 0.00013894736842105264,
      "loss": 0.5165,
      "step": 34
    },
    {
      "epoch": 0.32710280373831774,
      "grad_norm": 0.26328906416893005,
      "learning_rate": 0.0001368421052631579,
      "loss": 0.3968,
      "step": 35
    },
    {
      "epoch": 0.3364485981308411,
      "grad_norm": 0.3171282410621643,
      "learning_rate": 0.00013473684210526317,
      "loss": 0.5157,
      "step": 36
    },
    {
      "epoch": 0.34579439252336447,
      "grad_norm": 0.3076024055480957,
      "learning_rate": 0.00013263157894736842,
      "loss": 0.5744,
      "step": 37
    },
    {
      "epoch": 0.35514018691588783,
      "grad_norm": 0.2795088589191437,
      "learning_rate": 0.0001305263157894737,
      "loss": 0.4503,
      "step": 38
    },
    {
      "epoch": 0.3644859813084112,
      "grad_norm": 0.3355786204338074,
      "learning_rate": 0.00012842105263157895,
      "loss": 0.5448,
      "step": 39
    },
    {
      "epoch": 0.37383177570093457,
      "grad_norm": 0.362071692943573,
      "learning_rate": 0.0001263157894736842,
      "loss": 0.5761,
      "step": 40
    },
    {
      "epoch": 0.38317757009345793,
      "grad_norm": 0.30303430557250977,
      "learning_rate": 0.00012421052631578949,
      "loss": 0.4478,
      "step": 41
    },
    {
      "epoch": 0.3925233644859813,
      "grad_norm": 0.3056437075138092,
      "learning_rate": 0.00012210526315789474,
      "loss": 0.45,
      "step": 42
    },
    {
      "epoch": 0.40186915887850466,
      "grad_norm": 0.29585254192352295,
      "learning_rate": 0.00012,
      "loss": 0.5302,
      "step": 43
    },
    {
      "epoch": 0.411214953271028,
      "grad_norm": 0.3200451135635376,
      "learning_rate": 0.00011789473684210525,
      "loss": 0.5461,
      "step": 44
    },
    {
      "epoch": 0.4205607476635514,
      "grad_norm": 0.2822463810443878,
      "learning_rate": 0.00011578947368421053,
      "loss": 0.4859,
      "step": 45
    },
    {
      "epoch": 0.42990654205607476,
      "grad_norm": 0.3590220808982849,
      "learning_rate": 0.0001136842105263158,
      "loss": 0.6165,
      "step": 46
    },
    {
      "epoch": 0.4392523364485981,
      "grad_norm": 0.384006530046463,
      "learning_rate": 0.00011157894736842105,
      "loss": 0.5017,
      "step": 47
    },
    {
      "epoch": 0.4485981308411215,
      "grad_norm": 0.34835296869277954,
      "learning_rate": 0.00010947368421052633,
      "loss": 0.4517,
      "step": 48
    },
    {
      "epoch": 0.45794392523364486,
      "grad_norm": 0.29954054951667786,
      "learning_rate": 0.00010736842105263158,
      "loss": 0.5465,
      "step": 49
    },
    {
      "epoch": 0.4672897196261682,
      "grad_norm": 0.30959686636924744,
      "learning_rate": 0.00010526315789473685,
      "loss": 0.5085,
      "step": 50
    },
    {
      "epoch": 0.4766355140186916,
      "grad_norm": 0.3524712026119232,
      "learning_rate": 0.00010315789473684211,
      "loss": 0.627,
      "step": 51
    },
    {
      "epoch": 0.48598130841121495,
      "grad_norm": 0.3202904164791107,
      "learning_rate": 0.00010105263157894738,
      "loss": 0.5417,
      "step": 52
    },
    {
      "epoch": 0.4953271028037383,
      "grad_norm": 0.26235684752464294,
      "learning_rate": 9.894736842105263e-05,
      "loss": 0.5031,
      "step": 53
    },
    {
      "epoch": 0.5046728971962616,
      "grad_norm": 0.3092457354068756,
      "learning_rate": 9.68421052631579e-05,
      "loss": 0.584,
      "step": 54
    },
    {
      "epoch": 0.514018691588785,
      "grad_norm": 0.3472273051738739,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.5291,
      "step": 55
    },
    {
      "epoch": 0.5233644859813084,
      "grad_norm": 0.3596740961074829,
      "learning_rate": 9.263157894736843e-05,
      "loss": 0.4651,
      "step": 56
    },
    {
      "epoch": 0.5327102803738317,
      "grad_norm": 0.3216385841369629,
      "learning_rate": 9.052631578947369e-05,
      "loss": 0.5227,
      "step": 57
    },
    {
      "epoch": 0.5420560747663551,
      "grad_norm": 0.3339192867279053,
      "learning_rate": 8.842105263157894e-05,
      "loss": 0.5659,
      "step": 58
    },
    {
      "epoch": 0.5514018691588785,
      "grad_norm": 0.2907865345478058,
      "learning_rate": 8.631578947368421e-05,
      "loss": 0.4189,
      "step": 59
    },
    {
      "epoch": 0.5607476635514018,
      "grad_norm": 0.30216169357299805,
      "learning_rate": 8.421052631578948e-05,
      "loss": 0.4935,
      "step": 60
    },
    {
      "epoch": 0.5700934579439252,
      "grad_norm": 0.27054354548454285,
      "learning_rate": 8.210526315789474e-05,
      "loss": 0.3975,
      "step": 61
    },
    {
      "epoch": 0.5794392523364486,
      "grad_norm": 0.3534599840641022,
      "learning_rate": 8e-05,
      "loss": 0.6789,
      "step": 62
    },
    {
      "epoch": 0.5887850467289719,
      "grad_norm": 0.32607734203338623,
      "learning_rate": 7.789473684210526e-05,
      "loss": 0.5559,
      "step": 63
    },
    {
      "epoch": 0.5981308411214953,
      "grad_norm": 0.33004093170166016,
      "learning_rate": 7.578947368421054e-05,
      "loss": 0.4618,
      "step": 64
    },
    {
      "epoch": 0.6074766355140186,
      "grad_norm": 0.27141767740249634,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.422,
      "step": 65
    },
    {
      "epoch": 0.616822429906542,
      "grad_norm": 0.35549217462539673,
      "learning_rate": 7.157894736842105e-05,
      "loss": 0.51,
      "step": 66
    },
    {
      "epoch": 0.6261682242990654,
      "grad_norm": 0.30731022357940674,
      "learning_rate": 6.947368421052632e-05,
      "loss": 0.3812,
      "step": 67
    },
    {
      "epoch": 0.6355140186915887,
      "grad_norm": 0.35206177830696106,
      "learning_rate": 6.736842105263159e-05,
      "loss": 0.4554,
      "step": 68
    },
    {
      "epoch": 0.6448598130841121,
      "grad_norm": 0.26610609889030457,
      "learning_rate": 6.526315789473685e-05,
      "loss": 0.3403,
      "step": 69
    },
    {
      "epoch": 0.6542056074766355,
      "grad_norm": 0.3143245279788971,
      "learning_rate": 6.31578947368421e-05,
      "loss": 0.5061,
      "step": 70
    },
    {
      "epoch": 0.6635514018691588,
      "grad_norm": 0.29227766394615173,
      "learning_rate": 6.105263157894737e-05,
      "loss": 0.3927,
      "step": 71
    },
    {
      "epoch": 0.6728971962616822,
      "grad_norm": 0.341958612203598,
      "learning_rate": 5.894736842105263e-05,
      "loss": 0.474,
      "step": 72
    },
    {
      "epoch": 0.6822429906542056,
      "grad_norm": 0.2950492799282074,
      "learning_rate": 5.68421052631579e-05,
      "loss": 0.4741,
      "step": 73
    },
    {
      "epoch": 0.6915887850467289,
      "grad_norm": 0.3131846487522125,
      "learning_rate": 5.4736842105263165e-05,
      "loss": 0.4081,
      "step": 74
    },
    {
      "epoch": 0.7009345794392523,
      "grad_norm": 0.3440113067626953,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 0.503,
      "step": 75
    },
    {
      "epoch": 0.7102803738317757,
      "grad_norm": 0.3266673982143402,
      "learning_rate": 5.052631578947369e-05,
      "loss": 0.5833,
      "step": 76
    },
    {
      "epoch": 0.719626168224299,
      "grad_norm": 0.3489454984664917,
      "learning_rate": 4.842105263157895e-05,
      "loss": 0.4693,
      "step": 77
    },
    {
      "epoch": 0.7289719626168224,
      "grad_norm": 0.3095165193080902,
      "learning_rate": 4.6315789473684214e-05,
      "loss": 0.4145,
      "step": 78
    },
    {
      "epoch": 0.7383177570093458,
      "grad_norm": 0.3057728409767151,
      "learning_rate": 4.421052631578947e-05,
      "loss": 0.4854,
      "step": 79
    },
    {
      "epoch": 0.7476635514018691,
      "grad_norm": 0.28770875930786133,
      "learning_rate": 4.210526315789474e-05,
      "loss": 0.4656,
      "step": 80
    },
    {
      "epoch": 0.7570093457943925,
      "grad_norm": 0.32931607961654663,
      "learning_rate": 4e-05,
      "loss": 0.5494,
      "step": 81
    },
    {
      "epoch": 0.7663551401869159,
      "grad_norm": 0.2850057780742645,
      "learning_rate": 3.789473684210527e-05,
      "loss": 0.4019,
      "step": 82
    },
    {
      "epoch": 0.7757009345794392,
      "grad_norm": 0.34315744042396545,
      "learning_rate": 3.578947368421053e-05,
      "loss": 0.5148,
      "step": 83
    },
    {
      "epoch": 0.7850467289719626,
      "grad_norm": 0.3322080969810486,
      "learning_rate": 3.368421052631579e-05,
      "loss": 0.4572,
      "step": 84
    },
    {
      "epoch": 0.794392523364486,
      "grad_norm": 0.33055582642555237,
      "learning_rate": 3.157894736842105e-05,
      "loss": 0.5327,
      "step": 85
    },
    {
      "epoch": 0.8037383177570093,
      "grad_norm": 0.31167373061180115,
      "learning_rate": 2.9473684210526314e-05,
      "loss": 0.4383,
      "step": 86
    },
    {
      "epoch": 0.8130841121495327,
      "grad_norm": 0.32385683059692383,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 0.465,
      "step": 87
    },
    {
      "epoch": 0.822429906542056,
      "grad_norm": 0.28570225834846497,
      "learning_rate": 2.5263157894736845e-05,
      "loss": 0.4156,
      "step": 88
    },
    {
      "epoch": 0.8317757009345794,
      "grad_norm": 0.3011932671070099,
      "learning_rate": 2.3157894736842107e-05,
      "loss": 0.449,
      "step": 89
    },
    {
      "epoch": 0.8411214953271028,
      "grad_norm": 0.376464307308197,
      "learning_rate": 2.105263157894737e-05,
      "loss": 0.46,
      "step": 90
    },
    {
      "epoch": 0.8504672897196262,
      "grad_norm": 0.33849769830703735,
      "learning_rate": 1.8947368421052634e-05,
      "loss": 0.5506,
      "step": 91
    },
    {
      "epoch": 0.8598130841121495,
      "grad_norm": 0.32312753796577454,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 0.4742,
      "step": 92
    },
    {
      "epoch": 0.8691588785046729,
      "grad_norm": 0.3235548138618469,
      "learning_rate": 1.4736842105263157e-05,
      "loss": 0.4864,
      "step": 93
    },
    {
      "epoch": 0.8785046728971962,
      "grad_norm": 0.3346713185310364,
      "learning_rate": 1.2631578947368422e-05,
      "loss": 0.4226,
      "step": 94
    },
    {
      "epoch": 0.8878504672897196,
      "grad_norm": 0.33469706773757935,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.4355,
      "step": 95
    },
    {
      "epoch": 0.897196261682243,
      "grad_norm": 0.3326270282268524,
      "learning_rate": 8.421052631578948e-06,
      "loss": 0.4604,
      "step": 96
    },
    {
      "epoch": 0.9065420560747663,
      "grad_norm": 0.3249739706516266,
      "learning_rate": 6.315789473684211e-06,
      "loss": 0.4478,
      "step": 97
    },
    {
      "epoch": 0.9158878504672897,
      "grad_norm": 0.40442511439323425,
      "learning_rate": 4.210526315789474e-06,
      "loss": 0.5982,
      "step": 98
    },
    {
      "epoch": 0.9252336448598131,
      "grad_norm": 0.3419948220252991,
      "learning_rate": 2.105263157894737e-06,
      "loss": 0.4904,
      "step": 99
    },
    {
      "epoch": 0.9345794392523364,
      "grad_norm": 0.34674784541130066,
      "learning_rate": 0.0,
      "loss": 0.533,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1158219324407808.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
